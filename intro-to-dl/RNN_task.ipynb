{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "Copy of RNN-task.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YangJiao85/AdvancedML/blob/master/intro-to-dl/Copy_of_RNN_task.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7Xvno_nmf8n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set tf 1.x for colab\n",
        "%tensorflow_version 1.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CBn25kQmhRK",
        "colab_type": "code",
        "outputId": "001ddb8c-d53d-4610-d547-75c530a4af85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "source": [
        "! shred -u setup_google_colab.py\n",
        "! wget https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py -O setup_google_colab.py\n",
        "import setup_google_colab\n",
        "# please, uncomment the week you're working on\n",
        "# setup_google_colab.setup_week1()\n",
        "# setup_google_colab.setup_week2()\n",
        "# setup_google_colab.setup_week2_honor()\n",
        "# setup_google_colab.setup_week3()\n",
        "# setup_google_colab.setup_week4()\n",
        "setup_google_colab.setup_week5()\n",
        "# setup_google_colab.setup_week6()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shred: setup_google_colab.py: failed to open for writing: No such file or directory\n",
            "--2020-04-08 09:02:23--  https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3636 (3.6K) [text/plain]\n",
            "Saving to: ‘setup_google_colab.py’\n",
            "\n",
            "setup_google_colab. 100%[===================>]   3.55K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-04-08 09:02:24 (46.4 MB/s) - ‘setup_google_colab.py’ saved [3636/3636]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqD0qXC6mf84",
        "colab_type": "text"
      },
      "source": [
        "# Generating names with recurrent neural networks\n",
        "\n",
        "This time you'll find yourself delving into the heart (and other intestines) of recurrent neural networks on a class of toy problems.\n",
        "\n",
        "Struggle to find a name for the variable? Let's see how you'll come up with a name for your son/daughter. Surely no human has expertize over what is a good child name, so let us train RNN instead;\n",
        "\n",
        "It's dangerous to go alone, take these:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.696201Z",
          "start_time": "2018-08-13T20:26:38.104103Z"
        },
        "id": "t2AmmPj7mf9v",
        "colab_type": "code",
        "outputId": "e07d5acf-fea1-4031-c6a8-f82f5eb95a44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import os\n",
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "import keras_utils\n",
        "import tqdm_utils"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dB9V_yOumf90",
        "colab_type": "text"
      },
      "source": [
        "# Load data\n",
        "The dataset contains ~8k earthling names from different cultures, all in latin transcript.\n",
        "\n",
        "This notebook has been designed so as to allow you to quickly swap names for something similar: deep learning article titles, IKEA furniture, pokemon names, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.701832Z",
          "start_time": "2018-08-13T20:26:42.697766Z"
        },
        "id": "ixiG24hYmf91",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "start_token = \" \"  # so that the network knows that we're generating a first token\n",
        "\n",
        "# this is the token for padding,\n",
        "# we will add fake pad token at the end of names \n",
        "# to make them of equal size for further batching\n",
        "pad_token = \"#\"\n",
        "\n",
        "with open(\"names\") as f:\n",
        "    names = f.read()[:-1].split('\\n')\n",
        "    names = [start_token + name for name in names]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.707885Z",
          "start_time": "2018-08-13T20:26:42.703302Z"
        },
        "id": "xLiq7XvMmf93",
        "colab_type": "code",
        "outputId": "2be034cf-105e-4419-f484-a0c11aa97202",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        }
      },
      "source": [
        "print('number of samples:', len(names))\n",
        "for x in names[::1000]:\n",
        "    print(x)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of samples: 7944\n",
            " Abagael\n",
            " Claresta\n",
            " Glory\n",
            " Liliane\n",
            " Prissie\n",
            " Geeta\n",
            " Giovanne\n",
            " Piggy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.857411Z",
          "start_time": "2018-08-13T20:26:42.709371Z"
        },
        "id": "_NwpJC_9mf96",
        "colab_type": "code",
        "outputId": "8946ad0f-dd47-4a23-d760-15c0747df8a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "source": [
        "MAX_LENGTH = max(map(len, names))\n",
        "print(\"max length:\", MAX_LENGTH)\n",
        "\n",
        "plt.title('Sequence length distribution')\n",
        "plt.hist(list(map(len, names)), bins=25);"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max length: 16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQ9/MLCMOfTOzjPx/p/4cUF1Gcl0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0sWkMMrmf98",
        "colab_type": "text"
      },
      "source": [
        "# Text processing\n",
        "\n",
        "First we need to collect a \"vocabulary\" of all unique tokens i.e. unique characters. We can then encode inputs as a sequence of character ids."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.864592Z",
          "start_time": "2018-08-13T20:26:42.858725Z"
        },
        "id": "8FThO_r7mf98",
        "colab_type": "code",
        "outputId": "400d385e-ed44-46cf-a1af-7c5ace1280d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "tokens = set(''.join(names + [pad_token,]))  ### YOUR CODE HERE: all unique characters go here, padding included!\n",
        "\n",
        "tokens = list(tokens)\n",
        "n_tokens = len(tokens)\n",
        "print ('n_tokens:', n_tokens)\n",
        "\n",
        "assert 50 < n_tokens < 60"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "n_tokens: 56\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQDUlR4Tmf9-",
        "colab_type": "text"
      },
      "source": [
        "### Cast everything from symbols into identifiers\n",
        "\n",
        "Tensorflow string manipulation is a bit tricky, so we'll work around it. \n",
        "We'll feed our recurrent neural network with ids of characters from our dictionary.\n",
        "\n",
        "To create such dictionary, let's assign `token_to_id`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.870330Z",
          "start_time": "2018-08-13T20:26:42.866135Z"
        },
        "id": "JrBNwfHVmf9-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "token_to_id = {tokens[i]: i for i in range(len(tokens))} ### YOUR CODE HERE: create a dictionary of {symbol -> its  index in tokens}\n",
        "\n",
        "assert len(tokens) == len(token_to_id), \"dictionaries must have same size\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.875943Z",
          "start_time": "2018-08-13T20:26:42.871834Z"
        },
        "id": "drDMHaa4mf9_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_matrix(names, max_len=None, pad=token_to_id[pad_token], dtype=np.int32):\n",
        "    \"\"\"Casts a list of names into rnn-digestable padded matrix\"\"\"\n",
        "    \n",
        "    max_len = max_len or max(map(len, names))\n",
        "    names_ix = np.zeros([len(names), max_len], dtype) + pad\n",
        "\n",
        "    for i in range(len(names)):\n",
        "        name_ix = list(map(token_to_id.get, names[i]))\n",
        "        names_ix[i, :len(name_ix)] = name_ix\n",
        "\n",
        "    return names_ix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.883107Z",
          "start_time": "2018-08-13T20:26:42.877186Z"
        },
        "id": "aEm36hR6mf-A",
        "colab_type": "code",
        "outputId": "1e350081-1bdd-4e11-9615-9be50cf37782",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "source": [
        "# Example: cast 4 random names to padded matrices (so that we can easily batch them)\n",
        "print('\\n'.join(names[::2000]))\n",
        "print(to_matrix(names[::2000]))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Abagael\n",
            " Glory\n",
            " Prissie\n",
            " Giovanne\n",
            "[[31 17 25 45 28 45 54 34 37]\n",
            " [31 49 34 41 30 21 37 37 37]\n",
            " [31  4 30 35 13 13 35 54 37]\n",
            " [31 49 35 41 22 45 43 43 54]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3EIj5mMmf-C",
        "colab_type": "text"
      },
      "source": [
        "# Defining a recurrent neural network\n",
        "\n",
        "We can rewrite recurrent neural network as a consecutive application of dense layer to input $x_t$ and previous rnn state $h_t$. This is exactly what we're gonna do now.\n",
        "<img src=\"https://github.com/hse-aml/intro-to-dl/blob/master/week5/rnn.png?raw=1\" width=600>\n",
        "\n",
        "Since we're training a language model, there should also be:\n",
        "* An embedding layer that converts character id x_t to a vector.\n",
        "* An output layer that predicts probabilities of next phoneme based on h_t+1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.039419Z",
          "start_time": "2018-08-13T20:26:42.884581Z"
        },
        "id": "z4DKHt72mf-C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "64badbee-7942-4146-881e-c645a39e119e"
      },
      "source": [
        "# remember to reset your session if you change your graph!\n",
        "s = keras_utils.reset_tf_session()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/keras_utils.py:68: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:79: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:82: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:84: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/keras_utils.py:75: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/keras_utils.py:77: The name tf.InteractiveSession is deprecated. Please use tf.compat.v1.InteractiveSession instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.044903Z",
          "start_time": "2018-08-13T20:26:44.041084Z"
        },
        "id": "UiYJ3Qfjmf-D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.layers import concatenate, Dense, Embedding\n",
        "\n",
        "rnn_num_units = 64  # size of hidden state\n",
        "embedding_size = 16  # for characters\n",
        "\n",
        "# Let's create layers for our recurrent network\n",
        "# Note: we create layers but we don't \"apply\" them yet (this is a \"functional API\" of Keras)\n",
        "# Note: set the correct activation (from keras.activations) to Dense layers!\n",
        "\n",
        "# an embedding layer that converts character ids into embeddings\n",
        "embed_x = Embedding(n_tokens, embedding_size)\n",
        "\n",
        "# a dense layer that maps input and previous state to new hidden state, [x_t,h_t]->h_t+1\n",
        "get_h_next = Dense(rnn_num_units, activation='tanh')     ### YOUR CODE HERE\n",
        "\n",
        "# a dense layer that maps current hidden state to probabilities of characters [h_t+1]->P(x_t+1|h_t+1)\n",
        "get_probas = Dense(n_tokens, activation='softmax')       ### YOUR CODE HERE "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VhLc0wVmf-E",
        "colab_type": "text"
      },
      "source": [
        "We will generate names character by character starting with `start_token`:\n",
        "\n",
        "<img src=\"https://github.com/hse-aml/intro-to-dl/blob/master/week5/char-nn.png?raw=1\" width=600>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.053212Z",
          "start_time": "2018-08-13T20:26:44.048389Z"
        },
        "id": "JpVdzqhbmf-F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rnn_one_step(x_t, h_t):\n",
        "    \"\"\"\n",
        "    Recurrent neural network step that produces \n",
        "    probabilities for next token x_t+1 and next state h_t+1\n",
        "    given current input x_t and previous state h_t.\n",
        "    We'll call this method repeatedly to produce the whole sequence.\n",
        "    \n",
        "    You're supposed to \"apply\" above layers to produce new tensors.\n",
        "    Follow inline instructions to complete the function.\n",
        "    \"\"\"\n",
        "    # convert character id into embedding\n",
        "    x_t_emb = embed_x(tf.reshape(x_t, [-1, 1]))[:, 0]\n",
        "    \n",
        "    # concatenate x_t embedding and previous h_t state\n",
        "    x_and_h = concatenate([tf.reshape(x_t_emb,[-1,embedding_size]), h_t])       ### YOUR CODE HERE\n",
        "    \n",
        "    # compute next state given x_and_h\n",
        "    h_next = get_h_next(x_and_h)         ### YOUR CODE HERE\n",
        "    \n",
        "    # get probabilities for language model P(x_next|h_next)\n",
        "    output_probas = get_probas(h_next)   ### YOUR CODE HERE\n",
        "    \n",
        "    return output_probas, h_next"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99pTzX3mmf-G",
        "colab_type": "text"
      },
      "source": [
        "# RNN: loop\n",
        "\n",
        "Once `rnn_one_step` is ready, let's apply it in a loop over name characters to get predictions.\n",
        "\n",
        "Let's assume that all names are at most length-16 for now, so we can simply iterate over them in a for loop.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.342948Z",
          "start_time": "2018-08-13T20:26:44.056136Z"
        },
        "id": "66Vm0p4zmf-G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "e37c27f3-ce1b-475b-eac5-ce5926b4d552"
      },
      "source": [
        "input_sequence = tf.placeholder(tf.int32, (None, MAX_LENGTH))  # batch of token ids\n",
        "batch_size = tf.shape(input_sequence)[0]\n",
        "\n",
        "predicted_probas = []\n",
        "h_prev = tf.zeros([batch_size, rnn_num_units])  # initial hidden state\n",
        "\n",
        "for t in range(MAX_LENGTH):\n",
        "    x_t = input_sequence[:, t]  # column t\n",
        "    probas_next, h_next = rnn_one_step(x_t, h_prev)\n",
        "    \n",
        "    h_prev = h_next\n",
        "    predicted_probas.append(probas_next)\n",
        "    \n",
        "# combine predicted_probas into [batch, time, n_tokens] tensor\n",
        "predicted_probas = tf.transpose(tf.stack(predicted_probas), [1, 0, 2])\n",
        "\n",
        "# next to last token prediction is not needed\n",
        "predicted_probas = predicted_probas[:, :-1, :]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3535: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukHmY4vqmf-H",
        "colab_type": "text"
      },
      "source": [
        "# RNN: loss and gradients\n",
        "\n",
        "Let's gather a matrix of predictions for $P(x_{next}|h)$ and the corresponding correct answers.\n",
        "\n",
        "We will flatten our matrices to shape [None, n_tokens] to make it easier.\n",
        "\n",
        "Our network can then be trained by minimizing crossentropy between predicted probabilities and those answers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.354310Z",
          "start_time": "2018-08-13T20:26:44.344648Z"
        },
        "id": "nUC1AJrTmf-H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# flatten predictions to [batch*time, n_tokens]\n",
        "predictions_matrix = tf.reshape(predicted_probas, [-1, n_tokens])\n",
        "\n",
        "# flatten answers (next tokens) and one-hot encode them\n",
        "answers_matrix = tf.one_hot(tf.reshape(input_sequence[:, 1:], [-1]), n_tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6ffr2Iimf-I",
        "colab_type": "text"
      },
      "source": [
        "Usually it's a good idea to ignore gradients of loss for padding token predictions.\n",
        "\n",
        "Because we don't care about further prediction after the pad_token is predicted for the first time, so it doesn't make sense to punish our network after the pad_token is predicted.\n",
        "\n",
        "For simplicity you can ignore this comment, it's up to you."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:45.076642Z",
          "start_time": "2018-08-13T20:26:44.355594Z"
        },
        "id": "tJFe010gmf-I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "8fa50362-d4ec-4429-939c-4118a47c518c"
      },
      "source": [
        "# Define the loss as categorical cross-entropy (e.g. from keras.losses).\n",
        "# Mind that predictions are probabilities and NOT logits!\n",
        "# Remember to apply tf.reduce_mean to get a scalar loss!\n",
        "loss = tf.reduce_mean(keras.losses.categorical_crossentropy(answers_matrix, predictions_matrix))    ### YOUR CODE HERE\n",
        "\n",
        "optimize = tf.train.AdamOptimizer().minimize(loss)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2745: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2749: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzsD5F38mf-J",
        "colab_type": "text"
      },
      "source": [
        "# RNN: training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.322187Z",
          "start_time": "2018-08-13T20:26:45.078296Z"
        },
        "id": "QYMXcJytmf-K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "ffcb1dd4-ac14-4339-e546-93bea3778fb8"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "from random import sample\n",
        "\n",
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "batch_size = 32\n",
        "history = []\n",
        "\n",
        "for i in range(1000):\n",
        "    batch = to_matrix(sample(names, batch_size), max_len=MAX_LENGTH)\n",
        "    loss_i, _ = s.run([loss, optimize], {input_sequence: batch})\n",
        "    \n",
        "    history.append(loss_i)\n",
        "    \n",
        "    if (i + 1) % 100 == 0:\n",
        "        clear_output(True)\n",
        "        plt.plot(history, label='loss')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge\""
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSiWI/wfZnA5pnzeyiAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nqpk2yuLmf-L",
        "colab_type": "text"
      },
      "source": [
        "# RNN: sampling\n",
        "Once we've trained our network a bit, let's get to actually generating stuff. All we need is the `rnn_one_step` function you have written above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.341196Z",
          "start_time": "2018-08-13T20:26:55.323787Z"
        },
        "id": "LCI4WFNgmf-L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_t = tf.placeholder(tf.int32, (1,))\n",
        "h_t = tf.Variable(np.zeros([1, rnn_num_units], np.float32))  # we will update hidden state in this variable\n",
        "\n",
        "# For sampling we need to define `rnn_one_step` tensors only once in our graph.\n",
        "# We reuse all parameters thanks to functional API usage.\n",
        "# Then we can feed appropriate tensor values using feed_dict in a loop.\n",
        "# Note how different it is from training stage, where we had to unroll the whole sequence for backprop.\n",
        "next_probs, next_h = rnn_one_step(x_t, h_t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.346422Z",
          "start_time": "2018-08-13T20:26:55.342659Z"
        },
        "id": "UeSw5oD6mf-M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_sample(seed_phrase=start_token, max_length=MAX_LENGTH):\n",
        "    '''\n",
        "    This function generates text given a `seed_phrase` as a seed.\n",
        "    Remember to include start_token in seed phrase!\n",
        "    Parameter `max_length` is used to set the number of characters in prediction.\n",
        "    '''\n",
        "    x_sequence = [token_to_id[token] for token in seed_phrase]\n",
        "    s.run(tf.assign(h_t, h_t.initial_value))\n",
        "    \n",
        "    # feed the seed phrase, if any\n",
        "    for ix in x_sequence[:-1]:\n",
        "         s.run(tf.assign(h_t, next_h), {x_t: [ix]})\n",
        "    \n",
        "    # start generating\n",
        "    for _ in range(max_length-len(seed_phrase)):\n",
        "        x_probs,_ = s.run([next_probs, tf.assign(h_t, next_h)], {x_t: [x_sequence[-1]]})\n",
        "        x_sequence.append(np.random.choice(n_tokens, p=x_probs[0]))\n",
        "        \n",
        "    return ''.join([tokens[ix] for ix in x_sequence if tokens[ix] != pad_token])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:58.458115Z",
          "start_time": "2018-08-13T20:26:55.347900Z"
        },
        "id": "ZcaAh93ymf-N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "b60f8b94-8208-4be9-f345-4e6d4e1eff8c"
      },
      "source": [
        "# without prefix\n",
        "for _ in range(10):\n",
        "    print(generate_sample())"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Jryftrovee\n",
            " Joende\n",
            " Jiwy\n",
            " Korline\n",
            " Demetin\n",
            " Miri\n",
            " Qhrvojhan\n",
            " Waldi\n",
            " Datie\n",
            " Herla\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:01.986726Z",
          "start_time": "2018-08-13T20:26:58.459810Z"
        },
        "id": "ouZHQyhcmf-O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "888a3872-7783-47b0-d005-7f3577b782fc"
      },
      "source": [
        "# with prefix conditioning\n",
        "for _ in range(10):\n",
        "    print(generate_sample(' Trump'))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Trumpal\n",
            " Trumphay\n",
            " Trumpile\n",
            " Trumpi\n",
            " Trumpie-e\n",
            " Trumpe\n",
            " Trumpil\n",
            " Trumpatme\n",
            " Trumpy\n",
            " Trumpera\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhhN8l8Tmf-O",
        "colab_type": "text"
      },
      "source": [
        "# Submit to Coursera"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:40:02.004926Z",
          "start_time": "2018-08-13T20:40:02.000821Z"
        },
        "id": "0GfePl1Imf-P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# token expires every 30 min\n",
        "COURSERA_TOKEN = \"TJmJ3D9K9k5JpNif\"         \"### YOUR TOKEN HERE ###\"\n",
        "COURSERA_EMAIL = \"jiaoyang.cn@gmail.com\"    \"### YOUR EMAIL HERE ###\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:40:18.923357Z",
          "start_time": "2018-08-13T20:40:03.549343Z"
        },
        "id": "w2lwRoWgmf-Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "df0e28db-500a-49b0-fee7-572e3e1f9d7c"
      },
      "source": [
        "from submit import submit_char_rnn\n",
        "samples = [generate_sample(' Al') for i in tqdm_utils.tqdm_notebook_failsafe(range(25))]\n",
        "submission = (history, samples)\n",
        "submit_char_rnn(submission, COURSERA_EMAIL, COURSERA_TOKEN)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*************************\n",
            "\n",
            "You used an invalid email or your token may have expired. Please make sure you have entered all fields correctly. Try generating a new token if the issue still persists.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQ_fuJpTmf-R",
        "colab_type": "text"
      },
      "source": [
        "# Try it out!\n",
        "\n",
        "__Disclaimer:__ This part of assignment is entirely optional. You won't receive bonus points for it. However, it's a fun thing to do. Please share your results on course forums.\n",
        "\n",
        "You've just implemented a recurrent language model that can be tasked with generating any kind of sequence, so there's plenty of data you can try it on:\n",
        "\n",
        "* Novels/poems/songs of your favorite author\n",
        "* News titles/clickbait titles\n",
        "* Source code of Linux or Tensorflow\n",
        "* Molecules in [smiles](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) format\n",
        "* Melody in notes/chords format\n",
        "* IKEA catalog titles\n",
        "* Pokemon names\n",
        "* Cards from Magic, the Gathering / Hearthstone\n",
        "\n",
        "If you're willing to give it a try, here's what you wanna look at:\n",
        "* Current data format is a sequence of lines, so a novel can be formatted as a list of sentences. Alternatively, you can change data preprocessing altogether.\n",
        "* While some datasets are readily available, others can only be scraped from the web. Try `Selenium` or `Scrapy` for that.\n",
        "* Make sure MAX_LENGTH is adjusted for longer datasets. There's also a bonus section about dynamic RNNs at the bottom.\n",
        "* More complex tasks require larger RNN architecture, try more neurons or several layers. It would also require more training iterations.\n",
        "* Long-term dependencies in music, novels or molecules are better handled with LSTM or GRU\n",
        "\n",
        "__Good hunting!__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "P10_t1CNmf-R",
        "colab_type": "text"
      },
      "source": [
        "# Bonus level: dynamic RNNs\n",
        "\n",
        "Apart from Keras, there's also a friendly TensorFlow API for recurrent neural nets. It's based around the symbolic loop function (aka [tf.scan](https://www.tensorflow.org/api_docs/python/tf/scan)).\n",
        "\n",
        "RNN loop that we implemented for training can be replaced with single TensorFlow instruction: [tf.nn.dynamic_rnn](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn).\n",
        "This interface allows for dynamic sequence length and comes with some pre-implemented architectures.\n",
        "\n",
        "Take a look at [tf.nn.rnn_cell.BasicRNNCell](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicRNNCell)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:12.975354Z",
          "start_time": "2018-08-13T20:27:12.737529Z"
        },
        "id": "1Ay5J6wamf-R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "outputId": "82204f49-6449-4d1f-fcce-a7875e37536e"
      },
      "source": [
        "class CustomRNN(tf.nn.rnn_cell.BasicRNNCell):\n",
        "    def call(self, input, state):\n",
        "        # from docs:\n",
        "        # Returns:\n",
        "        # Output: A 2-D tensor with shape [batch_size, self.output_size].\n",
        "        # New state: Either a single 2-D tensor, or a tuple of tensors matching the arity and shapes of state.\n",
        "        return rnn_one_step(input[:, 0], state)\n",
        "    \n",
        "    @property\n",
        "    def output_size(self):\n",
        "        return n_tokens\n",
        "    \n",
        "cell = CustomRNN(rnn_num_units)\n",
        "\n",
        "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
        "    \n",
        "predicted_probas, last_state = tf.nn.dynamic_rnn(cell, input_sequence[:, :, None], dtype=tf.float32)\n",
        "\n",
        "print('LSTM outputs for each step [batch,time,n_tokens]:')\n",
        "print(predicted_probas.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-25-5f3812e903bf>:13: BasicRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.SimpleRNNCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From <ipython-input-25-5f3812e903bf>:17: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-5f3812e903bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0minput_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mpredicted_probas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdynamic_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_sequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'LSTM outputs for each step [batch,time,n_tokens]:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn.py\u001b[0m in \u001b[0;36mdynamic_rnn\u001b[0;34m(cell, inputs, sequence_length, initial_state, dtype, parallel_iterations, swap_memory, time_major, scope)\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0mswap_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswap_memory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m         \u001b[0msequence_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m         dtype=dtype)\n\u001b[0m\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m     \u001b[0;31m# Outputs of _dynamic_rnn_loop are always shaped [time, batch, depth].\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn.py\u001b[0m in \u001b[0;36m_dynamic_rnn_loop\u001b[0;34m(cell, inputs, initial_state, parallel_iterations, swap_memory, sequence_length, dtype)\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0mparallel_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparallel_iterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0mmaximum_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 916\u001b[0;31m       swap_memory=swap_memory)\n\u001b[0m\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m   \u001b[0;31m# Unpack final output if not using output tuples.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m   2751\u001b[0m       \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWHILE_CONTEXT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2752\u001b[0m     result = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants,\n\u001b[0;32m-> 2753\u001b[0;31m                                     return_same_structure)\n\u001b[0m\u001b[1;32m   2754\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmaximum_iterations\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2755\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mBuildLoop\u001b[0;34m(self, pred, body, loop_vars, shape_invariants, return_same_structure)\u001b[0m\n\u001b[1;32m   2243\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2244\u001b[0m         original_body_result, exit_vars = self._BuildLoop(\n\u001b[0;32m-> 2245\u001b[0;31m             pred, body, original_loop_vars, loop_vars, shape_invariants)\n\u001b[0m\u001b[1;32m   2246\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2247\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36m_BuildLoop\u001b[0;34m(self, pred, body, original_loop_vars, loop_vars, shape_invariants)\u001b[0m\n\u001b[1;32m   2168\u001b[0m         expand_composites=True)\n\u001b[1;32m   2169\u001b[0m     \u001b[0mpre_summaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2170\u001b[0;31m     \u001b[0mbody_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpacked_vars_for_body\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2171\u001b[0m     \u001b[0mpost_summaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2172\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sequence_or_composite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(i, lv)\u001b[0m\n\u001b[1;32m   2703\u001b[0m         cond = lambda i, lv: (  # pylint: disable=g-long-lambda\n\u001b[1;32m   2704\u001b[0m             math_ops.logical_and(i < maximum_iterations, orig_cond(*lv)))\n\u001b[0;32m-> 2705\u001b[0;31m         \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2706\u001b[0m       \u001b[0mtry_to_pack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn.py\u001b[0m in \u001b[0;36m_time_step\u001b[0;34m(time, output_ta_t, state)\u001b[0m\n\u001b[1;32m    882\u001b[0m           skip_conditionals=True)\n\u001b[1;32m    883\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m       \u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m     \u001b[0;31m# Keras cells always wrap state as list, even if it's a single tensor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    868\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_keras_rnn_cell\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 870\u001b[0;31m     \u001b[0mcall_cell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msequence_length\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn_cell_impl.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, state, scope, *args, **kwargs)\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# method.  See the class docstring for more details.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m     return base_layer.Layer.__call__(\n\u001b[0;32m--> 386\u001b[0;31m         self, inputs, state, scope=scope, *args, **kwargs)\n\u001b[0m\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/layers/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m       \u001b[0;31m# Actually call layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    822\u001b[0m           \u001b[0;31m# Build layer if applicable (if the `build` method has been\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    825\u001b[0m           \u001b[0mcast_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2144\u001b[0m         \u001b[0;31m# operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2145\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2146\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2147\u001b[0m       \u001b[0;31m# We must set self.built since user defined build functions are not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2148\u001b[0m       \u001b[0;31m# constrained to set self.built.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(instance, input_shape)\u001b[0m\n\u001b[1;32m    304\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m       \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_tuples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m     \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m     \u001b[0;31m# Return shapes from `fn` as TensorShapes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moutput_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn_cell_impl.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, inputs_shape)\u001b[0m\n\u001b[1;32m    449\u001b[0m       raise ValueError(\"Expected inputs.shape[-1] to be known, saw shape: %s\" %\n\u001b[1;32m    450\u001b[0m                        str(inputs_shape))\n\u001b[0;32m--> 451\u001b[0;31m     \u001b[0m_check_supported_dtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0minput_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn_cell_impl.py\u001b[0m in \u001b[0;36m_check_supported_dtypes\u001b[0;34m(dtype)\u001b[0m\n\u001b[1;32m   1345\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m     raise ValueError(\"RNN cell only supports floating point inputs, \"\n\u001b[0;32m-> 1347\u001b[0;31m                      \"but saw dtype: %s\" % dtype)\n\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m: RNN cell only supports floating point inputs, but saw dtype: <dtype: 'int32'>"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCtf4vCnmf-S",
        "colab_type": "text"
      },
      "source": [
        "Note that we never used MAX_LENGTH in the code above: TF will iterate over however many time-steps you gave it.\n",
        "\n",
        "You can also use any pre-implemented RNN cell:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:12.981697Z",
          "start_time": "2018-08-13T20:27:12.977590Z"
        },
        "id": "oj9XCWaLmf-S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for obj in dir(tf.nn.rnn_cell) + dir(tf.contrib.rnn):\n",
        "    if obj.endswith('Cell'):\n",
        "        print(obj, end=\"\\t\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:13.168207Z",
          "start_time": "2018-08-13T20:27:12.986884Z"
        },
        "id": "E8Ysz4Dvmf-T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
        "\n",
        "inputs_embedded = embed_x(input_sequence)\n",
        "\n",
        "# standard cell returns hidden state as output!\n",
        "cell = tf.nn.rnn_cell.LSTMCell(rnn_num_units)\n",
        "\n",
        "state_sequence, last_state = tf.nn.dynamic_rnn(cell, inputs_embedded, dtype=tf.float32)\n",
        "\n",
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "print('LSTM hidden state for each step [batch,time,rnn_num_units]:')\n",
        "print(state_sequence.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}